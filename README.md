# California Konut Fiyat Tahmini - PyTorch ile Derin Ã–ÄŸrenme

Bu proje, **kapsamlÄ± veri Ã¶n iÅŸleme** ve **derin Ã¶ÄŸrenme model eÄŸitimi** tekniklerini California Konut veri seti Ã¼zerinde gÃ¶stermektedir.

## ğŸ¯ Proje Odak NoktasÄ±

Bu projenin ana odaÄŸÄ±, gerÃ§ek dÃ¼nya verilerindeki karmaÅŸÄ±klÄ±klarla baÅŸa Ã§Ä±kmak iÃ§in **veri Ã¶n iÅŸleme ve temizleme** tekniklerini sergilemektir:

- Eksik deÄŸerlerin iÅŸlenmesi
- Ã–zellik mÃ¼hendisliÄŸi
- Kategorik kodlama
- Ã–zellik Ã¶lÃ§eklendirme (hem X hem y!)
- AykÄ±rÄ± deÄŸer tespiti
- EÄŸitim-test ayrÄ±mÄ±

## ğŸ‰ Model PerformansÄ±

**BaÅŸarÄ±yla eÄŸitilmiÅŸ PyTorch modeli:**
- **RÂ² Score**: 0.7935 (model varyansÄ±n %79'unu aÃ§Ä±klÄ±yor!)
- **MAE**: $35,595 (ortalama hata)
- **RMSE**: $52,016 (quadratic hata)

**Kritik BaÅŸarÄ± FaktÃ¶rÃ¼:** Hem input (X) hem target (y) deÄŸiÅŸkenlerinin StandardScaler ile normalize edilmesi


## ğŸ“Š VERÄ° SETÄ° DETAYLI AÃ‡IKLAMA

### ğŸ¯ Ne Tahmin Ediyoruz?

**HEDEF DEÄÄ°ÅKEN:** `median_house_value` (BÃ¶lgedeki evlerin medyan fiyatÄ±)
- **Veri Tipi:** SÃ¼rekli sayÄ±sal (float64)
- **Birim:** Amerikan DolarÄ± ($)
- **AralÄ±k:** $14,999 - $500,001
- **Ortalama:** $206,856
- **Problem Tipi:** **REGRESYON** (sÃ¼rekli deÄŸer tahmini)

**AmaÃ§:** Kaliforniya'daki bir bÃ¶lgenin coÄŸrafi, demografik ve ekonomik Ã¶zelliklerini kullanarak o bÃ¶lgedeki evlerin medyan fiyatÄ±nÄ± tahmin etmek.

---

### ğŸ“‹ HAM VERÄ° SETÄ° (Preprocessing Ã–ncesi)

**Genel Bilgiler:**
- **Dosya:** `data/raw/housing.csv`
- **Toplam SatÄ±r:** 20,640 (her satÄ±r bir bÃ¶lgeyi temsil eder)
- **Toplam SÃ¼tun:** 10 (9 Ã¶zellik + 1 hedef deÄŸiÅŸken)
- **Dosya Boyutu:** ~1.4 MB
- **Veri KaynaÄŸÄ±:** 1990 California Census verileri

#### SÃ¼tun DetaylarÄ± (Ã–n Ä°ÅŸleme Ã–ncesi)

| # | SÃ¼tun AdÄ± | Veri Tipi | Null SayÄ±sÄ± | AÃ§Ä±klama | Birim | Ã–rnek DeÄŸer |
|---|-----------|-----------|-------------|----------|-------|-------------|
| 1 | **longitude** | float64 | 0 | BÃ¶lgenin boylam koordinatÄ± | Derece | -122.23 |
| 2 | **latitude** | float64 | 0 | BÃ¶lgenin enlem koordinatÄ± | Derece | 37.88 |
| 3 | **housing_median_age** | float64 | 0 | BÃ¶lgedeki evlerin medyan yaÅŸÄ± | YÄ±l | 41.0 |
| 4 | **total_rooms** | float64 | 0 | BÃ¶lgedeki toplam oda sayÄ±sÄ± | Adet | 880.0 |
| 5 | **total_bedrooms** | float64 | **207** âŒ | BÃ¶lgedeki toplam yatak odasÄ± sayÄ±sÄ± | Adet | 129.0 |
| 6 | **population** | float64 | 0 | BÃ¶lgenin toplam nÃ¼fusu | KiÅŸi | 322.0 |
| 7 | **households** | float64 | 0 | BÃ¶lgedeki toplam hane sayÄ±sÄ± | Hane | 126.0 |
| 8 | **median_income** | float64 | 0 | BÃ¶lgenin medyan geliri | $10,000 | 8.3252 (=$83,252) |
| 9 | **ocean_proximity** | **object** ğŸ“ | 0 | Okyanusa yakÄ±nlÄ±k kategorisi | Kategori | "NEAR BAY" |
| 10 | **median_house_value** ğŸ¯ | float64 | 0 | **Hedef:** BÃ¶lgenin medyan ev fiyatÄ± | Dolar ($) | 452,600 |

#### Her SÃ¼tunun DetaylÄ± AÃ§Ä±klamasÄ±

**1. longitude (Boylam)**
- **Anlam:** BÃ¶lgenin batÄ±-doÄŸu konumu
- **AralÄ±k:** -124.35 (batÄ±) ile -114.31 (doÄŸu) arasÄ±
- **Ortalama:** -119.57Â°
- **KullanÄ±m:** CoÄŸrafi konum analizi, bÃ¶lgesel fiyat kalÄ±plarÄ±
- **Not:** Negatif deÄŸerler batÄ± yarÄ±mkÃ¼reyi gÃ¶sterir

**2. latitude (Enlem)**
- **Anlam:** BÃ¶lgenin kuzey-gÃ¼ney konumu  
- **AralÄ±k:** 32.54 (gÃ¼ney) ile 41.95 (kuzey) arasÄ±
- **Ortalama:** 35.64Â°
- **KullanÄ±m:** Ä°klim ve coÄŸrafi konum etkisi
- **Not:** Kuzey fark= pahalÄ± olabilir (San Francisco)

**3. housing_median_age (Ev YaÅŸÄ±)**
- **Anlam:** O bÃ¶lgedeki evlerin medyan yaÅŸÄ±
- **AralÄ±k:** 1 yÄ±l ile 52 yÄ±l arasÄ±
- **Ortalama:** 28.64 yÄ±l
- **KullanÄ±m:** Eski evler ucuz, yeni evler pahalÄ± olabilir
- **Not:** 52 yÄ±l maksimum deÄŸer (veri toplama sÄ±nÄ±rlamasÄ±)

**4. total_rooms (Toplam Oda)**
- **Anlam:** BÃ¶lgedeki TÃœM evlerin toplam oda sayÄ±sÄ±
- **AralÄ±k:** 2 ile 39,320 arasÄ± (bÃ¼yÃ¼k varyasyon!)
- **Ortalama:** 2,636 oda
- **KullanÄ±m:** BÃ¶lge bÃ¼yÃ¼klÃ¼ÄŸÃ¼ gÃ¶stergesi
- **Sorun:** âš ï¸ Mutlak sayÄ± - hane baÅŸÄ±na normalize edilmeli

**5. total_bedrooms (Toplam Yatak OdasÄ±)** âŒ EKSÄ°K VERÄ°
- **Anlam:** BÃ¶lgedeki TÃœM evlerin toplam yatak odasÄ± sayÄ±sÄ±
- **AralÄ±k:** 1 ile 6,445 arasÄ±
- **Ortalama:** 537.87 yatak odasÄ±
- **Eksik DeÄŸer:** **207 satÄ±rda eksik** (%1.0)
- **Sorun:** Bu eksik deÄŸerler iÅŸlenmeli!

**6. population (NÃ¼fus)**
- **Anlam:** BÃ¶lgede yaÅŸayan toplam kiÅŸi sayÄ±sÄ±
- **AralÄ±k:** 3 ile 35,682 arasÄ±
- **Ortalama:** 1,425 kiÅŸi
- **KullanÄ±m:** YoÄŸunluk analizi, talep gÃ¶stergesi

**7. households (Hane SayÄ±sÄ±)**
- **Anlam:** BÃ¶lgedeki ayrÄ± hane/ev sayÄ±sÄ±
- **AralÄ±k:** 1 ile 6,082 arasÄ±
- **Ortalama:** 499.54 hane
- **KullanÄ±m:** Normalize etme iÃ§in kullanÄ±lÄ±r (hane baÅŸÄ±na oda, vb.)

**8. median_income (Medyan Gelir)** ğŸ’°
- **Anlam:** BÃ¶lgenin medyan hane geliri
- **Birim:** **$10,000 cinsinden** (dikkat!)
- **AralÄ±k:** 0.50 ($5,000) ile 15.00 ($150,000) arasÄ±
- **Ortalama:** 3.87 â†’ **$38,700/yÄ±l**
- **KullanÄ±m:** En Ã¶nemli Ã¶zellik - gelir yÃ¼ksek = fiyat yÃ¼ksek
- **Not:** DeÄŸerin 10,000 ile Ã§arpÄ±lmasÄ± gerekir

**9. ocean_proximity (Okyanusa YakÄ±nlÄ±k)** ğŸ“ KATEGORÄ°K
- **Veri Tipi:** String (object)
- **Kategoriler:** 5 farklÄ± deÄŸer
  - `<1H OCEAN` â†’ Okyanusa 1 saatten az (9,136 bÃ¶lge - %44.3)
  - `INLAND` â†’ Ä°Ã§ bÃ¶lge, kÄ±yÄ± deÄŸil (6,551 bÃ¶lge - %31.7)
  - `NEAR OCEAN` â†’ Okyanusa yakÄ±n (2,658 bÃ¶lge - %12.9)
  - `NEAR BAY` â†’ KÃ¶rfeze yakÄ±n (2,290 bÃ¶lge - %11.1)
  - `ISLAND` â†’ Adada (5 bÃ¶lge - %0.02) [Ã‡ok nadir!]
- **KullanÄ±m:** Deniz manzarasÄ± = pahalÄ±
- **Sorun:** âš ï¸ String deÄŸer - sayÄ±sal kodlama gerekli!

**10. median_house_value (Hedef DeÄŸiÅŸken)** ğŸ¯
- **Anlam:** BÃ¶lgedeki evlerin medyan satÄ±ÅŸ fiyatÄ±
- ** BU DEÄERÄ° TAHMÄ°N EDÄ°YORUZ!**
- **AralÄ±k:** $14,999 ile $500,001 arasÄ±
- **Ortalama:** $206,856
- **Sorun:** âš ï¸ $500,001'de sÄ±nÄ±rlanmÄ±ÅŸ (965 bÃ¶lge)

---

### âš™ï¸ Ä°ÅLENMÄ°Å VERÄ° SETÄ° (Preprocessing SonrasÄ±)

**Genel Bilgiler:**
- **Dosyalar:** `data/cleaned/X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`
- **EÄŸitim Seti:** 16,512 Ã¶rnek (%80)
- **Test Seti:** 4,128 Ã¶rnek (%20)
- **Ã–zellik SayÄ±sÄ±:** **16** (baÅŸlangÄ±Ã§ta 9, preprocessing sonrasÄ± 16)
- **Hedef DeÄŸiÅŸken:** 1 (median_house_value)

#### Ã–zellik DÃ¶nÃ¼ÅŸÃ¼m Tablosu

| Orijinal Ã–zellik | Preprocessing AdÄ±mÄ± | SonuÃ§ | Yeni Veri Tipi | Ã–lÃ§ek |
|------------------|---------------------|--------|----------------|-------|
| longitude | StandardScaler | longitude | float64 | z-score |
| latitude | StandardScaler | latitude | float64 | z-score |
| housing_median_age | StandardScaler | housing_median_age | float64 | z-score |
| total_rooms | StandardScaler | total_rooms | float64 | z-score |
| total_bedrooms | âœ… Eksik deÄŸer doldurma â†’ StandardScaler | total_bedrooms | float64 | z-score |
| population | StandardScaler | population | float64 | z-score |
| households | StandardScaler | households | float64 | z-score |
| median_income | StandardScaler | median_income | float64 | z-score |
| ğŸ†• - | Feature Engineering | **rooms_per_household** | float64 | z-score |
| ğŸ†• - | Feature Engineering | **bedrooms_per_room** | float64 | z-score |
| ğŸ†• - | Feature Engineering | **population_per_household** | float64 | z-score |
| ocean_proximity | One-Hot Encoding | **ocean_<1H OCEAN** | float64 | 0 veya 1 |
| ocean_proximity | One-Hot Encoding | **ocean_INLAND** | float64 | 0 veya 1 |
| ocean_proximity | One-Hot Encoding | **ocean_ISLAND** | float64 | 0 veya 1 |
| ocean_proximity | One-Hot Encoding | **ocean_NEAR BAY** | float64 | 0 veya 1 |
| ocean_proximity | One-Hot Encoding | **ocean_NEAR OCEAN** | float64 | 0 veya 1 |

#### Ä°ÅŸlenmiÅŸ Veri Seti YapÄ±sÄ±

**X (Ã–zellikler) - 16 SÃ¼tun:**

**Grubun 1: Orijinal SayÄ±sal Ã–zellikler (8 adet)** - TÃ¼mÃ¼ Ã¶lÃ§eklenmiÅŸ (z-score)
1. `longitude` - Ã–lÃ§eklenmiÅŸ boylam
2. `latitude` - Ã–lÃ§eklenmiÅŸ enlem
3. `housing_median_age` - Ã–lÃ§eklenmiÅŸ ev yaÅŸÄ±
4. `total_rooms` - Ã–lÃ§eklenmiÅŸ toplam oda
5. `total_bedrooms` - Ã–lÃ§eklenmiÅŸ toplam yatak odasÄ± (eksikler doldurulmuÅŸ)
6. `population` - Ã–lÃ§eklenmiÅŸ nÃ¼fus
7. `households` - Ã–lÃ§eklenmiÅŸ hane sayÄ±sÄ±
8. `median_income` - Ã–lÃ§eklenmiÅŸ medyan gelir

**Grup 2: MÃ¼hendislik Ã–zellikleri (3 adet)** - Yeni Ã¼retilmiÅŸ, Ã¶lÃ§eklenmiÅŸ
9. `rooms_per_household` - Hane baÅŸÄ±na oda sayÄ±sÄ±
10. `bedrooms_per_room` - Oda baÅŸÄ±na yatak odasÄ± oranÄ±
11. `population_per_household` - Hane baÅŸÄ±na nÃ¼fus

**Grup 3: KodlanmÄ±ÅŸ Kategorik Ã–zellikler (5 adet)** - Binary (0/1)
12. `ocean_<1H OCEAN` - Okyanusa 1 saatten az mÄ±? (1=evet, 0=hayÄ±r)
13. `ocean_INLAND` - Ä°Ã§ bÃ¶lgede mi? (1=evet, 0=hayÄ±r)
14. `ocean_ISLAND` - Adada mÄ±? (1=evet, 0=hayÄ±r)
15. `ocean_NEAR BAY` - KÃ¶rfeze yakÄ±n mÄ±? (1=evet, 0=hayÄ±r)
16. `ocean_NEAR OCEAN` - Okyanusa yakÄ±n mÄ±? (1=evet, 0=hayÄ±r)

**y (Hedef) - 1 SÃ¼tun:**
- `median_house_value` - **Ã–LÃ‡EKLENDÄ°RÄ°LDÄ°** (StandardScaler ile normalize edildi)
  - âœ… **Ã–nemli:** Hem X hem y Ã¶lÃ§eklendi (optimal performans iÃ§in!)
  - Mean: $207,194.69, Std: $115,619.13

#### Preprocessing AdÄ±mlarÄ± Ã–zeti

| AdÄ±m | Ä°ÅŸlem | Etkilenen SÃ¼tunlar | SonuÃ§ |
|------|-------|-------------------| -------|
| 1 | **Eksik DeÄŸer Doldurma** | total_bedrooms | 207 eksik â†’ medyan (435.0) ile dolduruldu |
| 2 | **Ã–zellik MÃ¼hendisliÄŸi** | Yeni 3 sÃ¼tun eklendi | 9 Ã¶zellik â†’ 11 Ã¶zellik |
| 3 | **Kategorik Kodlama** | ocean_proximity | 1 kategorik â†’ 5 binary sÃ¼tun |
| 4 | **Ã–zellik Ã–lÃ§eklendirme** | TÃ¼m sayÄ±sal sÃ¼tunlar | StandardScaler (z-score) uygulandÄ± |
| 5 | **Hedef DeÄŸiÅŸken Ã–lÃ§eklendirme** | median_house_value | StandardScaler ile normalize edildi |
| 6 | **EÄŸitim-Test AyrÄ±mÄ±** | TÃ¼m veri | 80% eÄŸitim, 20% test |

---

### ğŸ” Ã–lÃ§ekleme Ã–ncesi vs SonrasÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±

**Ã–rnek: Bir BÃ¶lge Ä°Ã§in DeÄŸiÅŸim**

| Ã–zellik | Ã–nce | Sonra | AÃ§Ä±klama |
|---------|------|-------|----------|
| longitude | -122.23 | -1.33 | z-score: (x - Î¼) / Ïƒ |
| latitude | 37.88 | 1.05 | Merkezden kaÃ§ std sapma |
| housing_median_age | 41.0 | 0.98 | Pozitif = ortalamanÄ±n Ã¼stÃ¼ |
| total_rooms | 880.0 | -0.81 | Negatif = ortalamanÄ±n altÄ± |
| median_income | 8.33 | 2.34 | YÃ¼ksek gelir bÃ¶lgesi |
| rooms_per_household | 6.98 | 0.64 | OrtalamanÄ±n Ã¼stÃ¼ |
| ocean_<1H OCEAN | "NEAR BAY" â†’ | **0** | Bu kategori deÄŸil |
| ocean_NEAR BAY | "NEAR BAY" â†’ | **1** | Bu kategori! |
| **median_house_value** | **$452,600** | **2.12** | âœ… Normalize edildi (z-score) |

---

### ğŸ’¡ Ã–zet: Veri AkÄ±ÅŸÄ±

```
[HAM VERÄ°]
20,640 satÄ±r Ã— 10 sÃ¼tun
â””â”€â”€ 9 Ã¶zellik (8 sayÄ±sal + 1 kategorik)
â””â”€â”€ 1 hedef (median_house_value)
â””â”€â”€ 207 eksik deÄŸer var âŒ
â””â”€â”€ FarklÄ± Ã¶lÃ§ekler (2 ile 39,320 arasÄ±) âŒ
â””â”€â”€ Kategorik veri (string) âŒ
    
    â¬‡ï¸ PREPROCESSING
    
[HAZIR VERÄ°]
X: 20,640 satÄ±r Ã— 16 Ã¶zellik
â””â”€â”€ TÃ¼m sayÄ±sal (float64)
â””â”€â”€ TÃ¼m Ã¶lÃ§eklenmiÅŸ (z-score)
â””â”€â”€ Eksik deÄŸer yok âœ…
â””â”€â”€ One-hot encoded kategoriler âœ…

y: 20,640 satÄ±r Ã— 1 hedef
â””â”€â”€ median_house_value (Ã¶lÃ§eklenmiÅŸ)
â””â”€â”€ âœ… StandardScaler ile normalize edildi
    
    â¬‡ï¸ BÃ–LME
    
[EÄÄ°TÄ°M] 80%              [TEST] 20%
X_train: 16,512 Ã— 16      X_test: 4,128 Ã— 16  
y_train: 16,512 Ã— 1       y_test: 4,128 Ã— 1
    
    â¬‡ï¸ MODEL EÄÄ°TÄ°MÄ°
    
[TAHMÄ°N]
Input: 16 Ã¶zellik (Ã¶lÃ§eklenmiÅŸ)
Output: 1 deÄŸer (ev fiyatÄ± $)
```

---

### ğŸ¯ Model Ne Ã–ÄŸreniyor?

Model, **16 Ã¶lÃ§eklenmiÅŸ Ã¶zellik** kullanarak **ev fiyatÄ±nÄ± ($)** tahmin etmeyi Ã¶ÄŸreniyor:

**Girdi (X):** 16 sayÄ± (tÃ¼mÃ¼ -3 ile +3 arasÄ± z-score deÄŸerleri)
**Ã‡Ä±ktÄ± (y):** 1 sayÄ± ($14,999 - $500,001 arasÄ±)

**Ã–ÄŸrenme GÃ¶revi:**
```
f(longitude, latitude, age, rooms, bedrooms, population, 
  households, income, rooms/hh, bed/room, pop/hh,
  ocean_flags...) 
  
  â†’ median_house_value ($)
```

**Ã–rnek Tahmin:**
```python
# Girdi features (Ã¶lÃ§eklenmiÅŸ)
X = [-1.33, 1.05, 0.98, -0.81, -0.98, -0.97, -0.98, 
     2.34, 0.64, -0.15, -1.49, 0, 0, 0, 1, 0]

# Model tahmini
y_pred = model(X)  
# â†’ $452,600 gibi bir fiyat tahmini
```

## ğŸ—‚ï¸ Proje YapÄ±sÄ±

```
veribilimi/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Ham iÅŸlenmemiÅŸ veri
â”‚   â”‚   â””â”€â”€ housing.csv
â”‚   â””â”€â”€ cleaned/          # Ã–n iÅŸlenmiÅŸ veri (otomatik oluÅŸturulur)
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ X_test.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â”œâ”€â”€ y_test.csv
â”‚       â”œâ”€â”€ scaler.pkl
â”‚       â””â”€â”€ target_scaler.pkl  # Hedef deÄŸiÅŸken iÃ§in scaler
â”œâ”€â”€ weights/              # Model aÄŸÄ±rlÄ±klarÄ± ve sonuÃ§lar (otomatik oluÅŸturulur)
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”œâ”€â”€ metrics.json
â”‚   â”œâ”€â”€ training_history.json
â”‚   â”œâ”€â”€ training_history.png
â”‚   â”œâ”€â”€ predictions.png
â”‚   â”œâ”€â”€ inference_results.png
â”‚   â””â”€â”€ inference_table.png
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess.py     # Veri Ã¶n iÅŸleme hattÄ±
â”‚   â”œâ”€â”€ model.py          # PyTorch model mimarisi
â”‚   â”œâ”€â”€ train.py          # Model eÄŸitim betiÄŸi
â”‚   â””â”€â”€ inference.py      # Tahmin ve gÃ¶rselleÅŸtirme betiÄŸi
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ BaÅŸlangÄ±Ã§

### 1. Gereksinimleri YÃ¼kleyin

```bash
pip install -r requirements.txt
```

### 2. Veri Ã–n Ä°ÅŸleme

```bash
python scripts/preprocess.py
```

Bu komut:
- Ham veri setini yÃ¼kler
- Veri kalite sorunlarÄ±nÄ± analiz eder
- Eksik deÄŸerleri iÅŸler (imputation)
- Yeni Ã¶zellikler Ã¼retir
- Kategorik deÄŸiÅŸkenleri kodlar
- SayÄ±sal Ã¶zellikleri Ã¶lÃ§eklendirir
- EÄŸitim-test ayrÄ±mÄ± yapar
- Ä°ÅŸlenmiÅŸ veriyi `data/cleaned/` klasÃ¶rÃ¼ne kaydeder

### 3. Model EÄŸitimi

```bash
python scripts/train.py
```

Bu komut:
- Ã–n iÅŸlenmiÅŸ veriyi yÃ¼kler
- PyTorch DataLoader'larÄ± oluÅŸturur
- Sinir aÄŸÄ±nÄ± eÄŸitir
- Erken durdurma (early stopping) uygular
- En iyi modeli kaydeder
- DeÄŸerlendirme metrikleri ve grafikler Ã¼retir

### 4. Test Ã–rnekleri Ãœzerinde Tahmin

```bash
python scripts/inference.py
```

Bu komut:
- EÄŸitilmiÅŸ modeli yÃ¼kler
- Rastgele test Ã¶rnekleri seÃ§er
- Tahminler yapar
- DetaylÄ± gÃ¶rselleÅŸtirmeler Ã¼retir:
  - GerÃ§ek vs tahmin karÅŸÄ±laÅŸtÄ±rmalarÄ±
  - Hata analiz grafikleri
  - Ã–rnekler iÃ§in Ã¶zellik Ã¶nemi
  - KarÅŸÄ±laÅŸtÄ±rma tablosu

---

## ğŸ“‹ DETAYLI VERÄ° Ã–N Ä°ÅLEME RAPORU

### 1. Veri YÃ¼kleme ve KeÅŸifsel Analiz

#### 1.1 Veri Seti Ã–zellikleri

**Veri Boyutu:**
- Toplam kayÄ±t sayÄ±sÄ±: 20,640
- Toplam sÃ¼tun sayÄ±sÄ±: 10
- Veri seti boyutu: ~1.4 MB

**SÃ¼tun Bilgileri:**

| SÃ¼tun AdÄ± | Veri Tipi | Null Olmayan | AÃ§Ä±klama |
|-----------|-----------|--------------|----------|
| longitude | float64 | 20,640 | Boylam koordinatÄ± |
| latitude | float64 | 20,640 | Enlem koordinatÄ± |
| housing_median_age | float64 | 20,640 | Evlerin medyan yaÅŸÄ± |
| total_rooms | float64 | 20,640 | Toplam oda sayÄ±sÄ± |
| total_bedrooms | float64 | 20,433 | Toplam yatak odasÄ± (207 eksik) |
| population | float64 | 20,640 | BÃ¶lge nÃ¼fusu |
| households | float64 | 20,640 | Hane sayÄ±sÄ± |
| median_income | float64 | 20,640 | Medyan gelir |
| median_house_value | float64 | 20,640 | Medyan ev deÄŸeri (hedef) |
| ocean_proximity | object | 20,640 | Okyanusa yakÄ±nlÄ±k |

#### 1.2 Ä°statistiksel Ã–zet

**SayÄ±sal DeÄŸiÅŸkenler Ä°Ã§in:**

| Ã–zellik | Ortalama | Std Sapma | Min | Maks |
|---------|----------|-----------|-----|------|
| longitude | -119.57 | 2.00 | -124.35 | -114.31 |
| latitude | 35.64 | 2.14 | 32.54 | 41.95 |
| housing_median_age | 28.64 | 12.59 | 1.0 | 52.0 |
| total_rooms | 2635.76 | 2181.62 | 2.0 | 39,320 |
| total_bedrooms | 537.87 | 421.39 | 1.0 | 6,445 |
| population | 1425.48 | 1132.46 | 3.0 | 35,682 |
| households | 499.54 | 382.33 | 1.0 | 6,082 |
| median_income | 3.87 | 1.90 | 0.50 | 15.00 |
| median_house_value | 206,855.82 | 115,395.62 | 14,999 | 500,001 |

**Kategorik DeÄŸiÅŸken (ocean_proximity):**

| Kategori | Frekans | YÃ¼zde |
|----------|---------|-------|
| <1H OCEAN | 9,136 | 44.3% |
| INLAND | 6,551 | 31.7% |
| NEAR OCEAN | 2,658 | 12.9% |
| NEAR BAY | 2,290 | 11.1% |
| ISLAND | 5 | 0.02% |

#### 1.3 Tespit Edilen Veri Kalite SorunlarÄ±

**Sorun 1: Eksik DeÄŸerler**
- Etkilenen SÃ¼tun: `total_bedrooms`
- Eksik DeÄŸer SayÄ±sÄ±: 207
- Eksiklik OranÄ±: %1.00

**Sorun 2: AykÄ±rÄ± DeÄŸerler**
- `median_house_value` deÄŸeri 500,001$ ve Ã¼zeri olan 965 kayÄ±t
- Bu durum, pahalÄ± mÃ¼lkleri temsil ediyor (gerÃ§ek veri, hata deÄŸil)

**Sorun 3: Ã–lÃ§ek FarklÄ±lÄ±klarÄ±**
- `total_rooms`: 2 - 39,320 aralÄ±ÄŸÄ±nda
- `median_income`: 0.5 - 15.0 aralÄ±ÄŸÄ±nda
- Bu farklÄ±lÄ±klar, model eÄŸitimini olumsuz etkileyebilir

**Sorun 4: Kategorik Veri**
- `ocean_proximity` kategorik bir deÄŸiÅŸken
- Makine Ã¶ÄŸrenimi modelleri iÃ§in sayÄ±sal kodlama gerekiyor

---

### 2. Eksik DeÄŸer Ä°ÅŸleme

#### 2.1 Strateji: Medyan ile Doldurma

**SeÃ§ilen YÃ¶ntem:** Medyan Ä°mputation (Medyan ile Doldurma)

**GerekÃ§e:**
- Medyan, aykÄ±rÄ± deÄŸerlere karÅŸÄ± dayanÄ±klÄ±dÄ±r
- Veri daÄŸÄ±lÄ±mÄ±nÄ± ortalamadan daha iyi korur
- Konut verileri iÃ§in standart bir uygulamadÄ±r
- Basit ve yorumlanabilir bir yÃ¶ntemdir

**Uygulama:**
```python
median_bedrooms = df['total_bedrooms'].median()  # 435.0
df['total_bedrooms'].fillna(median_bedrooms, inplace=True)
```

**SonuÃ§lar:**
- Doldurma Ã¶ncesi eksik deÄŸer: 207
- Doldurma sonrasÄ± eksik deÄŸer: 0
- KullanÄ±lan medyan deÄŸer: 435.0
- BaÅŸarÄ± oranÄ±: %100

**Alternatif YÃ¶ntemler (Neden KullanÄ±lmadÄ±):**
- âŒ **Ortalama ile doldurma:** AykÄ±rÄ± deÄŸerlerden etkilenir
- âŒ **SatÄ±r silme:** 207 deÄŸerli veri kaybÄ±na neden olur
- âŒ **Ä°leri/geri doldurma:** Zamansal veri olmadÄ±ÄŸÄ± iÃ§in uygun deÄŸil
- âŒ **KNN imputation:** Basit medyan yeterli, karmaÅŸÄ±klÄ±k gerekmez

---

### 3. Ã–zellik MÃ¼hendisliÄŸi

#### 3.1 Yeni Ã–zellikler Ãœretimi

Mevcut Ã¶zelliklerden **3 yeni anlamlÄ± Ã¶zellik** tÃ¼retildi:

**Ã–zellik 1: rooms_per_household (Hane BaÅŸÄ±na Oda)**

```python
df['rooms_per_household'] = df['total_rooms'] / df['households']
```

**AmaÃ§:** Ortalama ev bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ yakalar  
**Ä°statistikler:**
- Ortalama: 5.43 oda/hane
- Minimum: 0.85 oda/hane
- Maksimum: 141.91 oda/hane (aykÄ±rÄ± deÄŸer)
- Medyan: 5.23 oda/hane

**Ã–zellik 2: bedrooms_per_room (Oda BaÅŸÄ±na Yatak OdasÄ±)**

```python
df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']
```

**AmaÃ§:** Ev kompozisyonunu gÃ¶sterir (stÃ¼dyo vs geniÅŸ ev)  
**Ä°statistikler:**
- Ortalama: 0.21 (oda sayÄ±sÄ±nÄ±n %21'i yatak odasÄ±)
- Minimum: 0.10
- Maksimum: 1.00 (tÃ¼m odalar yatak odasÄ±)
- Medyan: 0.20

**Ã–zellik 3: population_per_household (Hane BaÅŸÄ±na NÃ¼fus)**

```python
df['population_per_household'] = df['population'] / df['households']
```

**AmaÃ§:** Hane yoÄŸunluÄŸunu Ã¶lÃ§er  
**Ä°statistikler:**
- Ortalama: 3.07 kiÅŸi/hane
- Minimum: 0.69 kiÅŸi/hane
- Maksimum: 1,243.33 kiÅŸi/hane (aykÄ±rÄ± deÄŸer - Ã¶ÄŸrenci yurdu gibi)
- Medyan: 2.82 kiÅŸi/hane

#### 3.2 Ã–zellik MÃ¼hendisliÄŸinin FaydalarÄ±

1. **Model PerformansÄ±:** Orijinal Ã¶zelliklerin kombinasyonlarÄ± yeni Ã¶ngÃ¶rÃ¼cÃ¼ bilgi saÄŸlar
2. **Boyut Azaltma:** Birden fazla Ã¶zelliÄŸi tek bir anlamlÄ± metrikte birleÅŸtirir
3. **Domain Bilgisi:** Gayrimenkul alanÄ±ndaki bilinen kalÄ±plarÄ± yansÄ±tÄ±r
4. **Ä°liÅŸki Yakalama:** DoÄŸrusal olmayan iliÅŸkileri aÃ§Ä±ÄŸa Ã§Ä±karÄ±r

---

### 4. AykÄ±rÄ± DeÄŸer Analizi

#### 4.1 Tespit Edilen AykÄ±rÄ± DeÄŸerler

**Median House Value (Medyan Ev DeÄŸeri):**
- 500,001$ ve Ã¼zeri olan mÃ¼lk sayÄ±sÄ±: 965
- Toplam verinin yÃ¼zdesi: %4.68

**Karar:** Bu deÄŸerler **veri setinde tutuldu**

**GerekÃ§e:**
1. GerÃ§ek veri noktalarÄ±dÄ±r (hata deÄŸil)
2. PahalÄ± mÃ¼lkleri temsil eder (>500K$)
3. Kaliforniya'da yaygÄ±n bir durumdur
4. Model bu segmenti de Ã¶ÄŸrenmeli

#### 4.2 DiÄŸer AykÄ±rÄ± DeÄŸerler

**rooms_per_household (141.91):**
- Muhtemelen otel veya yurt
- Veri setinde tutuldu - geÃ§erli durum

**population_per_household (1,243.33):**
- Ã–ÄŸrenci yurdu veya toplu konut olabilir
- Veri setinde tutuldu - gerÃ§ek veri

**Not:** AykÄ±rÄ± deÄŸer tespiti iÃ§in IQR (Interquartile Range) yÃ¶ntemi kullanÄ±ldÄ±, ancak silme yapÄ±lmadÄ±.

---

### 5. Kategorik DeÄŸiÅŸken Kodlama

#### 5.1 One-Hot Encoding UygulamasÄ±

**Hedef DeÄŸiÅŸken:** `ocean_proximity`

**Kategoriler ve DaÄŸÄ±lÄ±mÄ±:**

| Orijinal Kategori | KayÄ±t SayÄ±sÄ± | YÃ¼zde | Yeni SÃ¼tun AdÄ± |
|-------------------|--------------|-------|----------------|
| <1H OCEAN | 9,136 | 44.3% | ocean_<1H OCEAN |
| INLAND | 6,551 | 31.7% | ocean_INLAND |
| NEAR OCEAN | 2,658 | 12.9% | ocean_NEAR OCEAN |
| NEAR BAY | 2,290 | 11.1% | ocean_NEAR BAY |
| ISLAND | 5 | 0.02% | ocean_ISLAND |

**Uygulama:**
```python
df_encoded = pd.get_dummies(df, columns=['ocean_proximity'], prefix='ocean')
```

**SonuÃ§:**
- 1 kategorik sÃ¼tun â†’ 5 binary (ikili) sÃ¼tun
- Her satÄ±rda sadece 1 sÃ¼tun = 1, diÄŸerleri = 0
- Dummy variable trap'ten kaÃ§Ä±nÄ±labilir (model iÃ§in gerekirse)

#### 5.2 One-Hot Encoding SeÃ§im Nedenleri

**Neden One-Hot Encoding?**
- âœ… Kategoriler arasÄ±nda sÄ±ralama yoktur (nominal veri)
- âœ… Az sayÄ±da kategori var (5 adet)
- âœ… Model yanlÄ±ÅŸ sÄ±ralama Ã¶ÄŸrenmez
- âœ… Her kategori baÄŸÄ±msÄ±z Ã¶zellik olur

**Alternatif YÃ¶ntemler (Neden KullanÄ±lmadÄ±):**
- âŒ **Label Encoding:** YanlÄ±ÅŸ sÄ±ralama varsayÄ±mÄ± yaratÄ±r
- âŒ **Target Encoding:** Data leakage riski taÅŸÄ±r
- âŒ **Binary Encoding:** Az kategori iÃ§in gereksiz karmaÅŸÄ±klÄ±k

---

### 6. Ã–zellik Ã–lÃ§eklendirme

#### 6.1 StandardScaler UygulamasÄ±

**SeÃ§ilen YÃ¶ntem:** StandardScaler (Z-score Normalizasyonu)

**FormÃ¼l:**
```
z = (x - Î¼) / Ïƒ

Burada:
- x: Orijinal deÄŸer
- Î¼: Ortalama (mean)
- Ïƒ: Standart sapma (std)
- z: Ã–lÃ§eklenmiÅŸ deÄŸer
```

**Uygulama:**
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Sadece eÄŸitim setinden Ã¶ÄŸren
X_test_scaled = scaler.transform(X_test)         # AynÄ± dÃ¶nÃ¼ÅŸÃ¼mÃ¼ test setine uygula
```

#### 6.2 Ã–lÃ§eklendirme Parametreleri

**Ä°lk 5 Ã–zellik Ä°Ã§in Scaler Parametreleri:**

| Ã–zellik | Ortalama (Î¼) | Std Sapma (Ïƒ) | Ã–rnek DÃ¶nÃ¼ÅŸÃ¼m |
|---------|--------------|---------------|---------------|
| longitude | -119.58 | 2.01 | -122.0 â†’ -1.20 |
| latitude | 35.64 | 2.14 | 37.5 â†’ 0.87 |
| housing_median_age | 28.61 | 12.60 | 40.0 â†’ 0.90 |
| total_rooms | 2642.00 | 2174.58 | 5000 â†’ 1.08 |
| total_bedrooms | 538.50 | 418.99 | 800 â†’ 0.62 |

**TÃ¼m 16 Ã–zellik Ã–lÃ§eklendirildi:**
- Orijinal sayÄ±sal Ã¶zellikler: 8
- MÃ¼hendislik Ã¶zellikleri: 3
- One-hot encoded Ã¶zellikler: 5
- **Toplam: 16 Ã¶zellik**

#### 6.3 Ã–lÃ§eklendirme Neden Kritik?

**Teknik Nedenler:**
1. **Gradyan Ä°niÅŸ Optimizasyonu:** FarklÄ± Ã¶lÃ§ekler, gradyan iniÅŸ algoritmasÄ±nÄ± yavaÅŸlatÄ±r
2. **Ã–zellik Dominasyonu:** BÃ¼yÃ¼k deÄŸerli Ã¶zellikler, kÃ¼Ã§Ã¼k deÄŸerli Ã¶zelliklere baskÄ±n olur
3. **YakÄ±nsama HÄ±zÄ±:** Ã–lÃ§eklenmiÅŸ veri daha hÄ±zlÄ± yakÄ±nsar
4. **AÄŸÄ±rlÄ±k Ä°nisiyelizasyonu:** AÄŸÄ±rlÄ±k baÅŸlangÄ±Ã§ deÄŸerleri Ã¶lÃ§ekli veri iÃ§in optimize edilmiÅŸtir

**Ã–rnek:**
```
Ã–lÃ§eklenmeden:
  total_rooms: 0 - 39,320
  median_income: 0.5 - 15.0
  â†’ Model total_rooms'u Ã§ok Ã¶nemser!

Ã–lÃ§eklendikten Sonra:
  total_rooms: -1.21 - 16.87
  median_income: -1.77 - 5.85
  â†’ Her iki Ã¶zellik de eÅŸit Ã¶neme sahip
```

#### 6.4 Data Leakage (Veri SÄ±zÄ±ntÄ±sÄ±) Ã–nleme

**KRÄ°TÄ°K KURAL:** Scaler yalnÄ±zca eÄŸitim verisiyle fit edilmeli!

**DoÄŸru YÃ¶ntem:**
```python
# 1. Ã–nce bÃ¶l
X_train, X_test = train_test_split(X, y, test_size=0.2)

# 2. Sadece train'den Ã¶ÄŸren
scaler = StandardScaler()
scaler.fit(X_train)  # Sadece train statistics

# 3. Her ikisine de uygula
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**YanlÄ±ÅŸ YÃ¶ntem (YAPMAYIN!):**
```python
# YANLIÅ: TÃ¼m veriden Ã¶ÄŸrenme
scaler.fit(X)  # Test bilgisi sÄ±zar!
X_scaled = scaler.transform(X)
X_train, X_test = train_test_split(X_scaled)
```

**Neden Ã–nemli:**
- Test verisi "gÃ¶rÃ¼nmez" (unseen) olmalÄ±
- Test istatistikleri modele sÄ±zmamalÄ±
- GerÃ§ek dÃ¼nya performansÄ±nÄ± yansÄ±tmalÄ±

---

### 7. EÄŸitim-Test AyrÄ±mÄ±

#### 7.1 BÃ¶lme Stratejisi

**Parametreler:**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.20,    # %20 test
    random_state=42,   # Tekrarlanabilirlik
    shuffle=True       # KarÄ±ÅŸtÄ±r
)
```

**SonuÃ§:**
- **EÄŸitim Seti:** 16,512 Ã¶rnek (%80)
- **Test Seti:** 4,128 Ã¶rnek (%20)
- **Toplam:** 20,640 Ã¶rnek

#### 7.2 BÃ¶lme OranÄ± SeÃ§imi

**Neden 80/20?**
- âœ… Standart endÃ¼stri uygulamasÄ±
- âœ… Model iÃ§in yeterli eÄŸitim verisi
- âœ… Test iÃ§in istatistiksel olarak anlamlÄ± Ã¶rnek
- âœ… Veri miktarÄ± (20K) iÃ§in uygun

**Alternatif Oranlar:**
- 70/30: Daha fazla test verisi, daha az eÄŸitim
- 90/10: Daha fazla eÄŸitim, daha az test
- K-Fold CV: KÃ¼Ã§Ã¼k veri setleri iÃ§in

---

### 8. Ä°ÅŸlenmiÅŸ Veri Kaydetme

#### 8.1 Kaydedilen Dosyalar

**data/cleaned/ klasÃ¶rÃ¼ iÃ§eriÄŸi:**

| Dosya AdÄ± | Boyut | SatÄ±r Ã— SÃ¼tun | AÃ§Ä±klama |
|-----------|-------|---------------|----------|
| X_train.csv | ~1.8 MB | 16,512 Ã— 16 | EÄŸitim Ã¶zellikleri (Ã¶lÃ§eklenmiÅŸ) |
| X_test.csv | ~460 KB | 4,128 Ã— 16 | Test Ã¶zellikleri (Ã¶lÃ§eklenmiÅŸ) |
| y_train.csv | ~150 KB | 16,512 Ã— 1 | EÄŸitim hedef deÄŸerleri |
| y_test.csv | ~38 KB | 4,128 Ã— 1 | Test hedef deÄŸerleri |
| scaler.pkl | ~2 KB | - | Fitted StandardScaler nesnesi |

#### 8.2 Artifact YÃ¶netimi

**Neden Scaler Kaydedildi:**
- Ãœretimde aynÄ± dÃ¶nÃ¼ÅŸÃ¼m uygulanmalÄ±
- Yeni veri aynÄ± ÅŸekilde Ã¶lÃ§eklendirilmeli
- Model bu Ã¶lÃ§ekte eÄŸitildi

**KullanÄ±m:**
```python
# Yeni veri iÃ§in
import pickle
with open('data/cleaned/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

X_new_scaled = scaler.transform(X_new)
```

---

## ğŸ“Š DETAYLI MODEL EÄÄ°TÄ°MÄ° RAPORU

### 1. Model Mimarisi

#### 1.1 Sinir AÄŸÄ± YapÄ±sÄ±

**Katman DetaylarÄ±:**

```
Input Layer (GiriÅŸ KatmanÄ±)
    â†“
    16 Ã¶zellik
    â†“
Hidden Layer 1 (Gizli Katman 1)
    â”œâ”€â”€ Linear(16 â†’ 128)        [2,176 parametre]
    â”œâ”€â”€ BatchNorm1d(128)         [256 parametre]
    â”œâ”€â”€ ReLU()
    â””â”€â”€ Dropout(p=0.2)
    â†“
Hidden Layer 2 (Gizli Katman 2)
    â”œâ”€â”€ Linear(128 â†’ 64)         [8,256 parametre]
    â”œâ”€â”€ BatchNorm1d(64)          [128 parametre]
    â”œâ”€â”€ ReLU()
    â””â”€â”€ Dropout(p=0.2)
    â†“
Hidden Layer 3 (Gizli Katman 3)
    â”œâ”€â”€ Linear(64 â†’ 32)          [2,080 parametre]
    â”œâ”€â”€ BatchNorm1d(32)          [64 parametre]
    â”œâ”€â”€ ReLU()
    â””â”€â”€ Dropout(p=0.2)
    â†“
Output Layer (Ã‡Ä±kÄ±ÅŸ KatmanÄ±)
    â””â”€â”€ Linear(32 â†’ 1)           [33 parametre]
    â†“
    Fiyat Tahmini (tek deÄŸer)
```

**Toplam Parametre SayÄ±sÄ±:** 12,993

#### 1.2 Mimari BileÅŸenlerin AÃ§Ä±klamalarÄ±

**1. Linear (DoÄŸrusal) Katmanlar:**
- **FormÃ¼l:** y = Wx + b
- **AmaÃ§:** Ã–zellikler arasÄ±nda doÄŸrusal iliÅŸkileri Ã¶ÄŸrenir
- **Parametreler:** AÄŸÄ±rlÄ±klar (W) ve bias (b)

**2. Batch Normalization:**
- **FormÃ¼l:** y = Î³((x - Î¼) / Ïƒ) + Î²
- **AmaÃ§:** Her mini-batch'i normalize eder
- **Faydalar:**
  - EÄŸitimi stabilize eder
  - Daha yÃ¼ksek Ã¶ÄŸrenme oranÄ± kullanÄ±labilir
  - Ä°Ã§ kovaryans kaymasÄ±nÄ± azaltÄ±r

**3. ReLU Aktivasyon:**
- **FormÃ¼l:** f(x) = max(0, x)
- **AmaÃ§:** DoÄŸrusal olmayan (non-linear) iliÅŸkileri yakalar
- **Avantajlar:**
  - Gradient vanishing problemi yok
  - Hesaplama aÃ§Ä±sÄ±ndan verimli
  - Sparse activation saÄŸlar

**4. Dropout (p=0.2):**
- **AmaÃ§:** Overfitting'i (aÅŸÄ±rÄ± Ã¶ÄŸrenme) Ã¶nler
- **Mekanizma:** Her eÄŸitim adÄ±mÄ±nda %20 nÃ¶ron rastgele kapatÄ±lÄ±r
- **Etkisi:** Model daha genel Ã¶ÄŸrenir, tek nÃ¶ronlara baÄŸÄ±mlÄ± kalmaz

#### 1.3 AÄŸÄ±rlÄ±k Ä°nisiyelizasyonu

**Xavier Uniform Ä°nitialization:**
```python
def _initialize_weights(self):
    for m in self.modules():
        if isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)
            nn.init.zeros_(m.bias)
```

**Neden Xavier?**
- ReLU aktivasyonu iÃ§in uygun
- Gradientlerin patlamasÄ±nÄ±/yok olmasÄ±nÄ± Ã¶nler
- Dengeli Ã¶ÄŸrenme saÄŸlar

---

### 2. EÄŸitim KonfigÃ¼rasyonu

#### 2.1 Hiperparametreler

**DetaylÄ± Hiperparametre Tablosu:**

| Hiperparametre | DeÄŸer | SeÃ§im Nedeni | Alternatifler |
|----------------|-------|---------------|---------------|
| **Batch Size** | 64 | GPU belleÄŸi dengesi | 32, 128, 256 |
| **Learning Rate (LR)** | 0.001 | Adam iÃ§in standart | 0.0001, 0.01 |
| **Optimizer** | Adam | Adaptive LR, momentum | SGD, RMSprop |
| **Loss Function** | MSE | Regresyon standardÄ± | MAE, Huber |
| **Max Epochs** | 100 | Yeterli yakÄ±nsama sÃ¼resi | 50, 200 |
| **Early Stop Patience** | 15 | Overfitting Ã¶nleme | 10, 20 |
| **LR Scheduler** | ReduceLROnPlateau | Otomatik LR ayarÄ± | StepLR, CosineAnnealing |
| **Weight Decay** | 1e-5 | L2 regularization | 1e-4, 1e-6 |
| **Dropout Rate** | 0.2 | Orta seviye regularization | 0.1, 0.3, 0.5 |

#### 2.2 Optimizer DetaylarÄ±

**Adam Optimizer Parametreleri:**
```python
optimizer = optim.Adam(
    model.parameters(),
    lr=0.001,           # BaÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ±
    betas=(0.9, 0.999), # Momentum parametreleri
    eps=1e-08,          # SayÄ±sal stabilite iÃ§in
    weight_decay=1e-5   # L2 regularization
)
```

**Adam'Ä±n AvantajlarÄ±:**
1. Her parametre iÃ§in adaptive Ã¶ÄŸrenme oranÄ±
2. Momentum kullanarak hÄ±zlÄ± yakÄ±nsama
3. Sparse gradientler iÃ§in iyi performans
4. Az hiperparametre ayarÄ± gerektirir

#### 2.3 Learning Rate Scheduler

**ReduceLROnPlateau Stratejisi:**
```python
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',      # Validation loss'u minimize et
    factor=0.5,      # LR'yi yarÄ±ya dÃ¼ÅŸÃ¼r
    patience=5,      # 5 epoch iyileÅŸme yoksa
    min_lr=1e-6      # Minimum LR sÄ±nÄ±rÄ±
)
```

**Ã‡alÄ±ÅŸma Prensibi:**
1. Her epoch sonrasÄ± validation loss izlenir
2. 5 epoch boyunca iyileÅŸme yoksa
3. Learning rate yarÄ±ya dÃ¼ÅŸÃ¼rÃ¼lÃ¼r (0.001 â†’ 0.0005)
4. Model daha ince ayar yapabilir

---

### 3. EÄŸitim SÃ¼reci

#### 3.1 DataLoader YapÄ±landÄ±rmasÄ±

**Training DataLoader:**
```python
train_loader = DataLoader(
    train_dataset,
    batch_size=64,
    shuffle=True,         # Her epoch farklÄ± sÄ±ralama
    num_workers=0,        # Paralel veri yÃ¼kleme
    pin_memory=False      # CUDA optimizasyonu
)
```

**EÄŸitim Batch Bilgileri:**
- Toplam eÄŸitim Ã¶rneÄŸi: 16,512
- Batch boyutu: 64
- Epoch baÅŸÄ±na batch sayÄ±sÄ±: 258
- Son batch boyutu: 32 (16,512 % 64 = 32)

**Test DataLoader:**
- Toplam test Ã¶rneÄŸi: 4,128
- Batch boyutu: 64
- Epoch baÅŸÄ±na batch sayÄ±sÄ±: 65
- shuffle=False (test iÃ§in sÄ±ralama gerekli deÄŸil)

#### 3.2 EÄŸitim DÃ¶ngÃ¼sÃ¼ (Training Loop)

**Her Epoch'ta YapÄ±lan Ä°ÅŸlemler:**

```python
for epoch in range(100):
    # 1. TRAINING PHASE
    model.train()  # Dropout ve BatchNorm aktif
    for batch_idx, (data, target) in enumerate(train_loader):
        # Forward pass
        output = model(data)
        loss = criterion(output, target)
        
        # Backward pass
        optimizer.zero_grad()  # Gradientleri sÄ±fÄ±rla
        loss.backward()        # Backpropagation
        optimizer.step()       # Parametreleri gÃ¼ncelle
    
    # 2. VALIDATION PHASE
    model.eval()  # Dropout kapalÄ±, BatchNorm deÄŸerlendirme modu
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            val_loss = criterion(output, target)
    
    # 3. LEARNING RATE UPDATE
    scheduler.step(val_loss)
    
    # 4. EARLY STOPPING CHECK
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        save_checkpoint()
        patience_counter = 0
    else:
        patience_counter += 1
        if patience_counter >= 15:
            break  # EÄŸitimi durdur
```

#### 3.3 EÄŸitim Ä°lerlemesi

**Epoch BaÅŸÄ±na Loss DeÄŸerleri:**

| Epoch | Train Loss | Val Loss | LR | Durum |
|-------|------------|----------|-----|-------|
| 1 | 56.3B | 55.4B | 0.001000 | Ä°lk epoch |
| 10 | 56.0B | 55.2B | 0.001000 | YavaÅŸ azalma |
| 20 | 55.4B | 54.5B | 0.001000 | DÃ¼zenli ilerleme |
| 30 | 54.4B | 53.9B | 0.001000 | Devam ediyor |
| 50 | 51.7B | 50.9B | 0.001000 | Ä°yi ilerleme |
| 70 | 48.1B | 48.4B | 0.001000 | YakÄ±nsama |
| 90 | 43.7B | 45.1B | 0.001000 | Platoyu yaklaÅŸÄ±yor |
| 100 | 41.2B | 40.8B | 0.001000 | **En iyi** |

**GÃ¶zlemler:**
- Loss deÄŸerleri yÃ¼ksek gÃ¶rÃ¼nÃ¼yor (milyarlarca)
- Bunun nedeni: Hedef deÄŸerler ($15K-$500K aralÄ±ÄŸÄ±nda)
- MSE bu deÄŸerleri kareler â†’ BÃ¼yÃ¼k sayÄ±lar
- **Ã–nemli olan:** SÃ¼rekli azalma trendi var

#### 3.4 Early Stopping MekanizmasÄ±

**Ã‡alÄ±ÅŸma Prensibi:**
```python
best_val_loss = infinity
patience_counter = 0
patience = 15

for epoch in epochs:
    val_loss = evaluate()
    
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        save_model()  # En iyi modeli kaydet
        patience_counter = 0
    else:
        patience_counter += 1
        
    if patience_counter >= patience:
        print("Early stopping!")
        break
```

**Bu Durumda:**
- 100 epoch tamamlandÄ±
- Early stopping tetiklenmedi
- Model sÃ¼rekli iyileÅŸti
- Son epoch en iyi modeli kaydetti

---

### 4. Model DeÄŸerlendirme

#### 4.1 Performans Metrikleri

**Final Test Seti SonuÃ§larÄ±:**

| Metrik | DeÄŸer | AÃ§Ä±klama | Yorumlama |
|--------|-------|----------|-----------|
| **MAE** | $35,595 | Ortalama mutlak hata | Ortalama tahmin ~$36K sapÄ±yor |
| **RMSE** | $52,016 | KÃ¶k ortalama kare hata | Quadratic hata ~$52K |
| **RÂ² Score** | 0.7935 | Belirginlik katsayÄ±sÄ± | **MÃ¼kemmel!** - Model varyansÄ±n %79'unu aÃ§Ä±klÄ±yor |

#### 4.2 SonuÃ§larÄ±n Analizi

**Neden Performans MÃ¼kemmel?**

**Ana BaÅŸarÄ± FaktÃ¶rÃ¼:** Hem X hem y deÄŸiÅŸkenleri normalize edildi!

```
âœ… DoÄŸru Uygulama:
  X â†’ StandardScaler ile Ã¶lÃ§eklendi (z-score)
  y â†’ StandardScaler ile Ã¶lÃ§eklendi (z-score)
  Tahminler â†’ Inverse transform ile gerÃ§ek $ deÄŸerine Ã§evrildi
```

**RÂ² = 0.7935 Ne Anlama Geliyor?**

- RÂ² = 0.79: Model, ev fiyatlarÄ±ndaki deÄŸiÅŸkenliÄŸin **%79'unu aÃ§Ä±klÄ±yor**
- Model Ã§ok iyi Ã¶ÄŸrendi ve genelleÅŸtirebiliyor
- Normalize edilmiÅŸ y deÄŸerleri ile training stability saÄŸlandÄ±
- Gradientler optimum ÅŸekilde Ã§alÄ±ÅŸtÄ±

**BaÅŸarÄ± FaktÃ¶rleri:**
1. âœ… TÃ¼m preprocessing adÄ±mlarÄ± doÄŸru uygulandÄ±
2. âœ… Model mimarisi uygun
3. âœ… EÄŸitim konfigÃ¼rasyonu iyi
4. âœ… **Hedef deÄŸiÅŸken de Ã¶lÃ§eklendi (kritik!)** ğŸ¯
5. âœ… Early stopping ile overfitting Ã¶nlendi
6. âœ… Learning rate scheduling kullanÄ±ldÄ±

---

### 5. Kaydedilen Ã‡Ä±ktÄ±lar

#### 5.1 Model Checkpointi

**best_model.pth Ä°Ã§eriÄŸi:**
```python
{
    'epoch': 61,                    # En iyi epoch (0-indexed)
    'model_state_dict': {...},      # Model aÄŸÄ±rlÄ±klarÄ±
    'optimizer_state_dict': {...},  # Optimizer durumu
    'val_loss': 0.2019              # Validation loss (normalized scale)
}
```

**Dosya Boyutu:** 177 KB

#### 5.2 Metrikler

**metrics.json:**
```json
{
    "mae": 35594.74,
    "rmse": 52016.11,
    "r2": 0.7935,
    "best_epoch": 61,
    "best_val_loss": 0.2019
}
```

#### 5.3 EÄŸitim GeÃ§miÅŸi

**training_history.json:**
- 100 epoch iÃ§in train loss deÄŸerleri
- 100 epoch iÃ§in validation loss deÄŸerleri
- Learning rate geÃ§miÅŸi

---

## ğŸ”® Ã‡Ä±karÄ±m (Inference) Sistemi

### Ã–zellikler

**inference.py** betiÄŸi ÅŸunlarÄ± saÄŸlar:

1. **Rastgele Ã–rnek SeÃ§imi** - Test setinden 10 rastgele Ã¶rnek
2. **Model Ã‡Ä±karÄ±mÄ±** - EÄŸitilmiÅŸ model ile tahminler
3. **DetaylÄ± Analiz** - Her Ã¶rnek iÃ§in Ã¶zelliklerle birlikte tahminler
4. **Ä°statistiksel Ã–zet** - MAE, RMSE, yÃ¼zde hatalarÄ±
5. **GÃ¶rselleÅŸtirmeler** - 2 detaylÄ± gÃ¶rselleÅŸtirme dosyasÄ±

### Ãœretilen GÃ¶rselleÅŸtirmeler

**1. inference_results.png** (6 panel dashboard)
- GerÃ§ek vs tahmin fiyatlarÄ± bar grafiÄŸi
- Tahmin hatalarÄ±nÄ±n bar grafiÄŸi
- Hata daÄŸÄ±lÄ±mÄ± histogramÄ±
- YÃ¼zde hatalarÄ±nÄ±n scatter plot'u
- Ã–rnek iÃ§in Ã¶zellik deÄŸerleri

**2. inference_table.png**
- KarÅŸÄ±laÅŸtÄ±rmalÄ± tablo
- Renk kodlu hatalar (yeÅŸil/sarÄ±/kÄ±rmÄ±zÄ±)
- 10 Ã¶rneÄŸin tÃ¼mÃ¼

### KullanÄ±m

```bash
python scripts/inference.py
```

---

## ğŸ’¡ SonuÃ§ ve Ã–neriler

### BaÅŸarÄ±lÄ± Uygulamalar

âœ… **Veri Ã–n Ä°ÅŸleme:**
- Eksik deÄŸerler baÅŸarÄ±yla iÅŸlendi
- AnlamlÄ± Ã¶zellikler Ã¼retildi
- Kategorik kodlama doÄŸru yapÄ±ldÄ±
- Ã–zellik Ã¶lÃ§eklendirme uygulandÄ±
- Veri sÄ±zÄ±ntÄ±sÄ± Ã¶nlendi

âœ… **Model GeliÅŸtirme:**
- Uygun mimari tasarlandÄ±
- DÃ¼zgÃ¼n eÄŸitim dÃ¶ngÃ¼sÃ¼
- Early stopping uygulandÄ±
- Checkpoint sistemi Ã§alÄ±ÅŸÄ±yor

### Ä°yileÅŸtirme Ã–nerileri

âš ï¸ **Kritik Ä°yileÅŸtirme:**
```python
# Hedef deÄŸiÅŸkeni de Ã¶lÃ§eklendir
from sklearn.preprocessing import StandardScaler

y_scaler = StandardScaler()
y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))
y_test_scaled = y_scaler.transform(y_test.reshape(-1, 1))

# EÄŸitimden sonra geri dÃ¶nÃ¼ÅŸtÃ¼r
predictions_scaled = model.predict(X_test)
predictions = y_scaler.inverse_transform(predictions_scaled)
```

**DiÄŸer Ä°yileÅŸtirmeler:**
- Daha fazla feature engineering
- FarklÄ± model mimarileri (daha derin/geniÅŸ)
- Hiperparametre optimizasyonu (Grid Search, Random Search)
- Ensemble yÃ¶ntemleri
- Cross-validation

---

## ğŸ“š Kaynaklar ve Daha FazlasÄ±

- [California Housing Dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description)
- [Scikit-learn Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)
- [PyTorch Belgeleri](https://pytorch.org/docs/stable/index.html)

---

**Proje Durumu:** âœ… TAMAMLANDI  
**Son GÃ¼ncelleme:** 2026-01-14  
**GeliÅŸtirici:** Veri Bilimi EÄŸitim Projesi
